import { getAIPredicatesWithCache, saveAIResponseToCache } from './database/cacheService'
import { OpenAIService } from './openaiService'
import { GeminiService } from './geminiService'

// Enhanced AI System Integration
import AIOrchestrator from './ai/AIOrchestrator'
import communicationLogger from './utils/AICommunicationLogger'
import { PredicateCandidate } from './utils/types/aiTypes'

// Feature Flags for Enhanced System
const FEATURE_FLAGS = {
  ENABLE_ENHANCED_AI: import.meta.env.VITE_ENABLE_ENHANCED_AI === 'true' || false,
  ENABLE_PARALLEL_AI: import.meta.env.VITE_ENABLE_PARALLEL_AI === 'true' || false,
  ENABLE_GPT4O_EVALUATION: import.meta.env.VITE_ENABLE_GPT4O_EVALUATION === 'true' || false,
  FALLBACK_TO_LEGACY: import.meta.env.VITE_FALLBACK_TO_LEGACY === 'true' || true
}

export class AIService {
  private static instance: AIService
  private openaiService: OpenAIService | null = null
  private geminiService: GeminiService | null = null
  
  // Enhanced AI System Components
  private aiOrchestrator: typeof AIOrchestrator | null = null
  private logger: typeof communicationLogger | null = null
  
  private constructor() {
    // OpenAI ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    const openaiApiKey = import.meta.env.VITE_OPENAI_API_KEY || import.meta.env.OPENAI_API_KEY
    if (openaiApiKey) {
      this.openaiService = OpenAIService.getInstance()
    }
    
    // Gemini ì„œë¹„ìŠ¤ ì´ˆê¸°í™”  
    const geminiApiKey = import.meta.env.VITE_GEMINI_API_KEY || import.meta.env.GEMINI_API_KEY
    if (geminiApiKey) {
      this.geminiService = new GeminiService(geminiApiKey)
    }
    
    // Enhanced AI System ì´ˆê¸°í™”
    if (FEATURE_FLAGS.ENABLE_ENHANCED_AI) {
      this.aiOrchestrator = AIOrchestrator
      this.logger = communicationLogger
      console.log('ğŸš€ [AI Service] Enhanced AI System í™œì„±í™”')
    } else {
      console.log('ğŸ“¦ [AI Service] Legacy AI System ì‚¬ìš©')
    }
  }
  
  public static getInstance(): AIService {
    if (!AIService.instance) {
      AIService.instance = new AIService()
    }
    return AIService.instance
  }
  
  async generatePredicates(noun: string): Promise<PredicateCandidate[]> {
    try {
      console.log(`ğŸ” [AI Service] ì„œìˆ ì–´ ìƒì„± ìš”ì²­: ${noun}`)
      
      // Enhanced AI System ì‚¬ìš© (Feature Flag í™•ì¸)
      if (FEATURE_FLAGS.ENABLE_ENHANCED_AI && this.aiOrchestrator) {
        return await this.generateWithEnhancedSystem(noun)
      }
      
      // Legacy System ì‚¬ìš© (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
      return await this.generateWithLegacySystem(noun)
      
    } catch (error) {
      console.error('ğŸš¨ [AI Service] ì„œìˆ ì–´ ìƒì„± ì˜¤ë¥˜:', error)
      
      // Feature Flagì— ë”°ë¥¸ í´ë°± ì „ëµ
      if (FEATURE_FLAGS.FALLBACK_TO_LEGACY && !FEATURE_FLAGS.ENABLE_ENHANCED_AI) {
        console.log('ğŸ”„ [AI Service] Legacy ì‹œìŠ¤í…œìœ¼ë¡œ í´ë°±')
        return await this.generateWithLegacySystem(noun)
      }
      
      // ìµœí›„ ìˆ˜ë‹¨: ì‘ê¸‰ ë¡œì»¬ í´ë°±
      const emergencyPredicates = this.getLocalBackupPredicates(noun)
      console.log(`ğŸ“ [AI Service] ì‘ê¸‰ í´ë°± ì‚¬ìš© - ë‹¨ì–´: ${noun}, ì‘ë‹µ: ${emergencyPredicates.length}ê°œ`)
      
      return emergencyPredicates
    }
  }
  
  // Enhanced AI System ì‹¤í–‰
  private async generateWithEnhancedSystem(noun: string): Promise<PredicateCandidate[]> {
    try {
      console.log(`ğŸš€ [AI Service] Enhanced AI System ì‹¤í–‰: ${noun}`)
      
      const result = await this.aiOrchestrator!.orchestrateRequest(noun)
      
      // ìƒì„¸ ë¡œê¹…
      if (this.logger) {
        const summary = this.logger.getSessionSummary()
        console.log(`ğŸ“Š [AI Service] Enhanced ì„¸ì…˜ ìš”ì•½: ${summary}`)
      }
      
      console.log(`âœ… [AI Service] Enhanced ì‹œìŠ¤í…œ ì„±ê³µ: ${result.predicates.length}ê°œ (${result.source}, ${result.processingTime}ms)`)
      
      return result.predicates
      
    } catch (error) {
      console.error('âŒ [AI Service] Enhanced AI System ì‹¤íŒ¨:', error)
      
      // Legacyë¡œ í´ë°± ì‹œë„
      if (FEATURE_FLAGS.FALLBACK_TO_LEGACY) {
        console.log('ğŸ”„ [AI Service] Enhanced â†’ Legacy í´ë°±')
        return await this.generateWithLegacySystem(noun)
      }
      
      throw error
    }
  }
  
  // Legacy System ì‹¤í–‰ (ê¸°ì¡´ ë¡œì§)
  private async generateWithLegacySystem(noun: string): Promise<PredicateCandidate[]> {
    console.log(`ğŸ“¦ [AI Service] Legacy AI System ì‹¤í–‰: ${noun}`)
    
    // 1. ìºì‹œ í™•ì¸ ë° OpenAI ëª¨ë¸ ê²€ì¦
    const cacheResult = await getAIPredicatesWithCache(noun)
    if (cacheResult.fromCache) {
      const isOpenAIModel = this.isOpenAIModel(cacheResult.modelName)
      
      if (isOpenAIModel) {
        // OpenAI ëª¨ë¸ë¡œ ìƒì„±ëœ ìºì‹œëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©
        console.log(`ğŸ¯ [AI Service] OpenAI ìºì‹œ ì ì¤‘: ${noun} (ëª¨ë¸: ${cacheResult.modelName})`)
        return cacheResult.response
      } else {
        // ë‹¤ë¥¸ ëª¨ë¸ë¡œ ìƒì„±ëœ ìºì‹œëŠ” OpenAIë¡œ 1íšŒ ì¬ì‹œë„
        console.log(`ğŸ”„ [AI Service] ë¹„-OpenAI ìºì‹œ ë°œê²¬: ${noun} (ëª¨ë¸: ${cacheResult.modelName}) - OpenAI ì¬ì‹œë„`)
        const openAIRetry = await this.retryWithOpenAI(noun)
        if (openAIRetry) {
          return openAIRetry
        }
        
        // OpenAI ì¬ì‹œë„ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ìºì‹œ ì‚¬ìš©
        console.log(`âš ï¸ [AI Service] OpenAI ì¬ì‹œë„ ì‹¤íŒ¨, ê¸°ì¡´ ìºì‹œ ì‚¬ìš©: ${noun}`)
        return cacheResult.response
      }
    }
    
    // 2. ì‹¤ì œ AI API í˜¸ì¶œ
    const response = await this.callAIAPI(noun)
    
    if (response && response.predicates.length > 0) {
      console.log(`âœ… [AI Service] Legacy API ì„œìˆ ì–´ ìƒì„± ì„±ê³µ: ${noun}`)
      
      // 3. API ì‘ë‹µì„ ìºì‹œì— ì €ì¥ (ë©”íƒ€ë°ì´í„° í¬í•¨)
      await saveAIResponseToCache(noun, response.predicates, response.modelName, true)
      
      return response.predicates
    }
    
    // 4. API ì‹¤íŒ¨ ì‹œ ë¡œì»¬ í´ë°± (ìºì‹œí•˜ì§€ ì•ŠìŒ)
    console.log(`âš ï¸ [AI Service] Legacy API ì‹¤íŒ¨, ë¡œì»¬ í´ë°± ì‚¬ìš©: ${noun}`)
    const localPredicates = this.getLocalBackupPredicates(noun)
    
    // 5. í´ë°± ì‚¬ìš© ë¡œê·¸ë§Œ ì¶œë ¥ (DBì— ì €ì¥í•˜ì§€ ì•ŠìŒ)
    console.log(`ğŸ“ [AI Service] Legacy ë¡œì»¬ í´ë°± ì‚¬ìš© - ë‹¨ì–´: ${noun}, ì‘ë‹µ: ${localPredicates.length}ê°œ (DB ì €ì¥ ì•ˆí•¨)`)
    
    return localPredicates
  }
  
  private isOpenAIModel(modelName?: string): boolean {
    if (!modelName) return false
    // OpenAI ëª¨ë¸ëª… íŒ¨í„´ í™•ì¸
    return modelName.includes('gpt') || modelName.toLowerCase().includes('openai')
  }
  
  private async retryWithOpenAI(noun: string): Promise<PredicateCandidate[] | null> {
    // OpenAI ì„œë¹„ìŠ¤ë§Œ ì‚¬ìš©í•˜ì—¬ ì¬ì‹œë„
    if (!this.openaiService) {
      console.log(`âŒ [AI Service] OpenAI ì„œë¹„ìŠ¤ ì—†ìŒ, ì¬ì‹œë„ ë¶ˆê°€`)
      return null
    }
    
    try {
      console.log(`ğŸ¤– [AI Service] OpenAI ë‹¨ë… ì¬ì‹œë„: ${noun}`)
      const openaiResult = await this.openaiService.generatePredicates(noun)
      
      if (openaiResult && openaiResult.length > 0) {
        console.log(`âœ… [AI Service] OpenAI ì¬ì‹œë„ ì„±ê³µ: ${openaiResult.length}ê°œ ì„œìˆ ì–´`)
        
        // ì¬ì‹œë„ ì„±ê³µ ì‹œ ì‘ë‹µì„ ìºì‹œì— ì €ì¥
        await saveAIResponseToCache(noun, openaiResult, 'gpt-3.5-turbo', true)
        
        return openaiResult
      }
      
      return null
    } catch (error) {
      console.warn(`âš ï¸ [AI Service] OpenAI ì¬ì‹œë„ ì‹¤íŒ¨:`, error)
      return null
    }
  }
  
  private async callAIAPI(noun: string): Promise<{ predicates: PredicateCandidate[], modelName: string } | null> {
    // OpenAI â†’ Gemini â†’ Local Fallback ìš°ì„ ìˆœìœ„ ì ìš©
    
    // 1. OpenAI ì„œë¹„ìŠ¤ ì‹œë„
    if (this.openaiService) {
      try {
        console.log(`ğŸ¤– [AI Service] OpenAI ì‹œë„ ì¤‘: ${noun}`)
        const openaiResult = await this.openaiService.generatePredicates(noun)
        if (openaiResult && openaiResult.length > 0) {
          console.log(`âœ… [AI Service] OpenAI ì„±ê³µ: ${openaiResult.length}ê°œ ì„œìˆ ì–´`)
          return { predicates: openaiResult, modelName: 'gpt-3.5-turbo' }
        }
      } catch (error) {
        console.warn(`âš ï¸ [AI Service] OpenAI ì‹¤íŒ¨:`, error)
      }
    }
    
    // 2. Gemini ì„œë¹„ìŠ¤ ì‹œë„
    if (this.geminiService) {
      try {
        console.log(`ğŸ¤– [AI Service] Gemini ì‹œë„ ì¤‘: ${noun}`)
        const geminiResult = await this.geminiService.generatePredicates(noun)
        if (geminiResult && geminiResult.length > 0) {
          console.log(`âœ… [AI Service] Gemini ì„±ê³µ: ${geminiResult.length}ê°œ ì„œìˆ ì–´`)
          return { predicates: geminiResult, modelName: 'gemini-2.5-flash-lite' }
        }
      } catch (error) {
        console.warn(`âš ï¸ [AI Service] Gemini ì‹¤íŒ¨:`, error)
      }
    }
    
    // 3. ëª¨ë“  AI ì„œë¹„ìŠ¤ ì‹¤íŒ¨
    console.log(`âŒ [AI Service] ëª¨ë“  AI ì„œë¹„ìŠ¤ ì‹¤íŒ¨: ${noun}`)
    return null
  }
  
  private getLocalBackupPredicates(noun: string): PredicateCandidate[] {
    // ê°„ë‹¨í•œ ë¡œì»¬ ë¶„ì„ ë¡œì§
    const category = this.analyzeNounCategory(noun)
    
    switch (category) {
      case 'place':
        return [
          { text: 'ì— ê°€ê³  ì‹¶ì–´ìš”', emoji: 'ğŸš¶', category: 'place' },
          { text: 'ì— ìˆì–´ìš”', emoji: 'ğŸ ', category: 'place' },
          { text: 'ì´ ì¢‹ì•„ìš”', emoji: 'ğŸ˜Š', category: 'general' },
          { text: 'ì—ì„œ ì‰¬ê³  ì‹¶ì–´ìš”', emoji: 'ğŸ˜´', category: 'place' }
        ]
      
      case 'food':
        return [
          { text: 'ì„ ë¨¹ê³  ì‹¶ì–´ìš”', emoji: 'ğŸ½ï¸', category: 'food' },
          { text: 'ì´ ë§›ìˆì–´ìš”', emoji: 'ğŸ˜‹', category: 'food' },
          { text: 'ì„ ì£¼ì„¸ìš”', emoji: 'ğŸ¤²', category: 'general' },
          { text: 'ì´ í•„ìš”í•´ìš”', emoji: 'ğŸ¤—', category: 'general' }
        ]
      
      case 'activity':
        return [
          { text: 'ì„ í•˜ê³  ì‹¶ì–´ìš”', emoji: 'ğŸ™Œ', category: 'activity' },
          { text: 'ì´ ì¢‹ì•„ìš”', emoji: 'ğŸ˜Š', category: 'general' },
          { text: 'ì´ ì¬ë¯¸ìˆì–´ìš”', emoji: 'ğŸ˜„', category: 'general' },
          { text: 'ì„ ë°°ìš°ê³  ì‹¶ì–´ìš”', emoji: 'ğŸ“š', category: 'activity' }
        ]
      
      case 'person':
        return [
          { text: 'ê°€ ì¢‹ì•„ìš”', emoji: 'ğŸ˜Š', category: 'general' },
          { text: 'ë¥¼ ë§Œë‚˜ê³  ì‹¶ì–´ìš”', emoji: 'ğŸ¤—', category: 'person' },
          { text: 'ê°€ ë³´ê³  ì‹¶ì–´ìš”', emoji: 'ğŸ’•', category: 'person' },
          { text: 'ë¥¼ ë„ì™€ì£¼ì„¸ìš”', emoji: 'ğŸ™', category: 'general' }
        ]
      
      default:
        return [
          { text: 'ì´ ì¢‹ì•„ìš”', emoji: 'ğŸ˜Š', category: 'general' },
          { text: 'ì´ í•„ìš”í•´ìš”', emoji: 'ğŸ¤²', category: 'general' },
          { text: 'ì„ ì›í•´ìš”', emoji: 'ğŸ™Œ', category: 'general' },
          { text: 'ì„ ë„ì™€ì£¼ì„¸ìš”', emoji: 'ğŸ™', category: 'general' }
        ]
    }
  }
  
  private analyzeNounCategory(noun: string): string {
    const places = ['í™”ì¥ì‹¤', 'í•™êµ', 'ì§‘', 'ë³‘ì›', 'ì‹œì¥', 'ê³µì›', 'ë„ì„œê´€', 'ì‹ë‹¹', 'ì¹´í˜', 'ë†€ì´í„°', 'ìˆ˜ì˜ì¥', 'ì²´ìœ¡ê´€']
    const foods = ['ë°¥', 'ë¬¼', 'ë¹µ', 'ìš°ìœ ', 'ê³¼ì', 'ì‚¬ê³¼', 'ë°”ë‚˜ë‚˜', 'ê¹€ì¹˜', 'ë¼ë©´', 'í”¼ì', 'ì¹˜í‚¨', 'í–„ë²„ê±°']
    const activities = ['ìˆ˜ì˜', 'ê³µë¶€', 'ë†€ì´', 'ìš´ë™', 'ë…ì„œ', 'ê·¸ë¦¼', 'ìŒì•…', 'ê²Œì„', 'ì‚°ì±…', 'ìš”ë¦¬']
    const people = ['ì—„ë§ˆ', 'ì•„ë¹ ', 'ì„ ìƒë‹˜', 'ì¹œêµ¬', 'í• ë¨¸ë‹ˆ', 'í• ì•„ë²„ì§€', 'ì–¸ë‹ˆ', 'ì˜¤ë¹ ', 'ë™ìƒ']
    
    if (places.includes(noun)) return 'place'
    if (foods.includes(noun)) return 'food'
    if (activities.includes(noun)) return 'activity'
    if (people.includes(noun)) return 'person'
    
    // ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± ë¶„ì„
    if (noun.includes('ì‹¤') || noun.includes('ì¥')) return 'place'
    if (noun.includes('ìŒë£Œ') || noun.includes('ì‹')) return 'food'
    if (noun.includes('ë†€') || noun.includes('ê²Œì„')) return 'activity'
    
    return 'general'
  }
  
  // Enhanced AI System ê´€ë¦¬ ë©”ì„œë“œë“¤
  
  // ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ
  public async getSystemStatus(): Promise<{
    mode: 'enhanced' | 'legacy'
    healthy: boolean
    features: typeof FEATURE_FLAGS
    performance?: any
  }> {
    const mode = FEATURE_FLAGS.ENABLE_ENHANCED_AI ? 'enhanced' : 'legacy'
    
    if (mode === 'enhanced' && this.aiOrchestrator) {
      const status = await this.aiOrchestrator.getSystemStatus()
      return {
        mode,
        healthy: status.healthy,
        features: FEATURE_FLAGS,
        performance: status.performance
      }
    }
    
    // Legacy ëª¨ë“œ ìƒíƒœ
    const legacyHealthy = !!(this.openaiService || this.geminiService)
    
    return {
      mode,
      healthy: legacyHealthy,
      features: FEATURE_FLAGS
    }
  }
  
  // ì„±ëŠ¥ ë³´ê³ ì„œ ì¡°íšŒ (Enhanced ëª¨ë“œì—ì„œë§Œ)
  public getPerformanceReport(): any {
    if (FEATURE_FLAGS.ENABLE_ENHANCED_AI && this.aiOrchestrator) {
      return this.aiOrchestrator.getPerformanceReport()
    }
    
    return {
      summary: 'Legacy mode - detailed metrics not available',
      recommendations: ['Enhanced AI ì‹œìŠ¤í…œì„ í™œì„±í™”í•˜ì—¬ ìƒì„¸ ë©”íŠ¸ë¦­ì„ í™•ì¸í•˜ì„¸ìš”'],
      metrics: {}
    }
  }
  
  // Feature Flag ìƒíƒœ ì¡°íšŒ
  public getFeatureFlags(): typeof FEATURE_FLAGS {
    return { ...FEATURE_FLAGS }
  }
  
  // Enhanced AI System ì„¤ì • ì¡°íšŒ (Enhanced ëª¨ë“œì—ì„œë§Œ)
  public getEnhancedConfig(): any {
    if (FEATURE_FLAGS.ENABLE_ENHANCED_AI && this.aiOrchestrator) {
      return this.aiOrchestrator.getConfig()
    }
    
    return null
  }
  
  // í†µì‹  ë¡œê·¸ ìš”ì•½ ì¡°íšŒ (Enhanced ëª¨ë“œì—ì„œë§Œ)
  public getCommunicationSummary(): string {
    if (FEATURE_FLAGS.ENABLE_ENHANCED_AI && this.logger) {
      return this.logger.getSessionSummary()
    }
    
    return 'Legacy mode - communication logging not available'
  }
  
  // ì‹œìŠ¤í…œ ë¦¬ì…‹ (Enhanced ëª¨ë“œì—ì„œë§Œ)
  public resetEnhancedSystem(): void {
    if (FEATURE_FLAGS.ENABLE_ENHANCED_AI && this.aiOrchestrator) {
      this.aiOrchestrator.reset()
      console.log('ğŸ”„ [AI Service] Enhanced AI System ë¦¬ì…‹ ì™„ë£Œ')
    } else {
      console.log('âš ï¸ [AI Service] Enhanced AI Systemì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤')
    }
  }
  
  // ë””ë²„ê¹… ì •ë³´ ì œê³µ
  public getDebugInfo(): {
    mode: string
    flags: typeof FEATURE_FLAGS
    legacyServices: {
      openai: boolean
      gemini: boolean
    }
    enhancedStatus?: any
  } {
    const debugInfo = {
      mode: FEATURE_FLAGS.ENABLE_ENHANCED_AI ? 'enhanced' : 'legacy',
      flags: FEATURE_FLAGS,
      legacyServices: {
        openai: !!this.openaiService,
        gemini: !!this.geminiService
      }
    }
    
    if (FEATURE_FLAGS.ENABLE_ENHANCED_AI && this.aiOrchestrator) {
      return {
        ...debugInfo,
        enhancedStatus: this.aiOrchestrator.getConfig()
      }
    }
    
    return debugInfo
  }
}

export default AIService.getInstance()