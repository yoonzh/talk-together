import { Client } from '@libsql/client'

export interface Migration {
  id: string
  description: string
  sql: string
  rollback?: string
}

export const migrations: Migration[] = [
  {
    id: '001_initial_schema',
    description: 'Create initial database schema',
    sql: `
      -- AI ì„œìˆ ì–´ ìºì‹œ í…Œì´ë¸”
      CREATE TABLE IF NOT EXISTS ai_predicate_cache (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        input_word VARCHAR(100) NOT NULL,
        ai_response TEXT NOT NULL,
        model_name VARCHAR(50) NOT NULL,
        response_source VARCHAR(20) DEFAULT 'api',
        response_hash VARCHAR(64) UNIQUE,
        created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
        expires_at DATETIME,
        access_count INTEGER DEFAULT 1,
        last_accessed_at DATETIME DEFAULT CURRENT_TIMESTAMP
      );

      CREATE INDEX IF NOT EXISTS idx_input_word ON ai_predicate_cache(input_word);
      CREATE INDEX IF NOT EXISTS idx_expires_at ON ai_predicate_cache(expires_at);
      CREATE INDEX IF NOT EXISTS idx_response_source ON ai_predicate_cache(response_source);

      -- TTS ì˜¤ë””ì˜¤ ìºì‹œ í…Œì´ë¸”
      CREATE TABLE IF NOT EXISTS tts_audio_cache (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        sentence_text TEXT NOT NULL,
        sentence_hash VARCHAR(64) UNIQUE NOT NULL,
        audio_data TEXT,
        compression_type VARCHAR(20) DEFAULT 'base64_gzip',
        audio_format VARCHAR(10) DEFAULT 'mp3',
        duration_ms INTEGER,
        file_size_bytes INTEGER,
        compressed_size_bytes INTEGER,
        voice_config TEXT,
        tts_provider VARCHAR(20) DEFAULT 'gcp',
        is_api_generated BOOLEAN DEFAULT TRUE,
        created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
        access_count INTEGER DEFAULT 1,
        last_accessed_at DATETIME DEFAULT CURRENT_TIMESTAMP
      );

      CREATE INDEX IF NOT EXISTS idx_sentence_hash ON tts_audio_cache(sentence_hash);
      CREATE INDEX IF NOT EXISTS idx_is_api_generated ON tts_audio_cache(is_api_generated);

      -- ì‹œìŠ¤í…œ ì„¤ì • í…Œì´ë¸”
      CREATE TABLE IF NOT EXISTS system_settings (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        setting_key VARCHAR(100) UNIQUE NOT NULL,
        setting_value TEXT,
        description TEXT,
        updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
      );

      -- ê¸°ë³¸ ì„¤ì •ê°’ ì‚½ì…
      INSERT OR IGNORE INTO system_settings (setting_key, setting_value, description) VALUES
      ('ai_cache_duration_months', '3', 'AI ì„œìˆ ì–´ ìºì‹œ ìœ ì§€ ê¸°ê°„ (ê°œì›”)'),
      ('tts_cache_max_size_mb', '100', 'TTS ì˜¤ë””ì˜¤ ìºì‹œ ìµœëŒ€ í¬ê¸° (MB)'),
      ('db_schema_version', '1.0.0', 'ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ë²„ì „');
    `,
    rollback: `
      DROP TABLE IF EXISTS ai_predicate_cache;
      DROP TABLE IF EXISTS tts_audio_cache;
      DROP TABLE IF EXISTS system_settings;
    `
  },
  {
    id: '002_usage_logs',
    description: 'Add usage logging table',
    sql: `
      CREATE TABLE IF NOT EXISTS usage_logs (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        user_id INTEGER,
        action_type VARCHAR(50) NOT NULL,
        input_data TEXT,
        response_data TEXT,
        cache_hit BOOLEAN DEFAULT FALSE,
        cache_eligible BOOLEAN DEFAULT TRUE,
        fallback_reason VARCHAR(100),
        processing_time_ms INTEGER,
        created_at DATETIME DEFAULT CURRENT_TIMESTAMP
      );

      CREATE INDEX IF NOT EXISTS idx_action_type ON usage_logs(action_type);
      CREATE INDEX IF NOT EXISTS idx_cache_hit ON usage_logs(cache_hit);
      CREATE INDEX IF NOT EXISTS idx_cache_eligible ON usage_logs(cache_eligible);
    `,
    rollback: `DROP TABLE IF EXISTS usage_logs;`
  }
]

export class MigrationManager {
  private client: Client

  constructor(client: Client) {
    this.client = client
  }

  async createMigrationsTable(): Promise<void> {
    await this.client.execute(`
      CREATE TABLE IF NOT EXISTS schema_migrations (
        id VARCHAR(50) PRIMARY KEY,
        description TEXT,
        applied_at DATETIME DEFAULT CURRENT_TIMESTAMP
      );
    `)
  }

  async getAppliedMigrations(): Promise<string[]> {
    const result = await this.client.execute('SELECT id FROM schema_migrations ORDER BY applied_at')
    return result.rows.map((row: any) => row.id as string)
  }

  async applyMigration(migration: Migration): Promise<void> {
    console.log(`ğŸ“¦ [DB] ë§ˆì´ê·¸ë ˆì´ì…˜ ì ìš©: ${migration.id} - ${migration.description}`)
    
    try {
      // SQL ë¬¸ì¥ì„ ê°œë³„ì ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ì‹¤í–‰
      const sqlStatements = this.splitSqlStatements(migration.sql)
      
      // ê° SQL ë¬¸ì¥ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰ (batch ëŒ€ì‹  ê°œë³„ ì‹¤í–‰)
      for (let i = 0; i < sqlStatements.length; i++) {
        const statement = sqlStatements[i].trim()
        console.log(`ğŸ”§ [Migration] SQL ì‹¤í–‰ ${i + 1}/${sqlStatements.length}: ${statement.substring(0, 50)}...`)
        
        await this.client.execute(statement)
        console.log(`âœ… [Migration] SQL ì™„ë£Œ ${i + 1}/${sqlStatements.length}`)
      }
      
      // ë§ˆì´ê·¸ë ˆì´ì…˜ ê¸°ë¡ ì¶”ê°€
      await this.client.execute(
        'INSERT INTO schema_migrations (id, description) VALUES (?, ?)',
        [migration.id, migration.description]
      )
      
      console.log(`âœ… [DB] ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ: ${migration.id}`)
      
    } catch (error) {
      console.error(`âŒ [Migration] ì‹¤í–‰ ì‹¤íŒ¨: ${migration.id}`, error)
      throw error
    }
  }

  private splitSqlStatements(sql: string): string[] {
    // SQL ë¬¸ì¥ì„ ì„¸ë¯¸ì½œë¡ ìœ¼ë¡œ ë¶„ë¦¬ (ì£¼ì„ ì œê±° ë° ì •ë¦¬)
    
    // 1. ì£¼ì„ ë¼ì¸ ì œê±° (-- ë¡œ ì‹œì‘í•˜ëŠ” ë¼ì¸ ì „ì²´ ì œê±°)
    const cleanedSql = sql
      .split('\n')
      .filter(line => !line.trim().startsWith('--'))
      .join('\n')
    
    // 2. ì„¸ë¯¸ì½œë¡ ìœ¼ë¡œ ë¶„ë¦¬í•˜ê³  ì •ë¦¬
    const statements = cleanedSql
      .split(';')
      .map(statement => statement.trim())
      .filter(statement => statement.length > 0)
    
    // 3. ë””ë²„ê¹…ì„ ìœ„í•œ ë¡œê·¸ ì¶œë ¥
    console.log(`ğŸ” [Migration] SQL ë¶„ë¦¬ ê²°ê³¼ (${statements.length}ê°œ ë¬¸ì¥):`)
    statements.forEach((stmt, idx) => {
      console.log(`${idx + 1}. ${stmt.substring(0, 50)}...`)
    })
    
    return statements.map(statement => statement + ';')
  }

  async rollbackMigration(migration: Migration): Promise<void> {
    if (!migration.rollback) {
      throw new Error(`ë§ˆì´ê·¸ë ˆì´ì…˜ ${migration.id}ì— ë¡¤ë°± ìŠ¤í¬ë¦½íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤`)
    }

    console.log(`ğŸ”„ [DB] ë§ˆì´ê·¸ë ˆì´ì…˜ ë¡¤ë°±: ${migration.id}`)
    
    // ë¡¤ë°± SQLë„ ë¶„ë¦¬í•˜ì—¬ ì‹¤í–‰
    const sqlStatements = this.splitSqlStatements(migration.rollback)
    const batchCommands: Array<{ sql: string; args?: any[] }> = sqlStatements.map(sql => ({ sql: sql.trim() }))
    
    // ë§ˆì´ê·¸ë ˆì´ì…˜ ê¸°ë¡ ì‚­ì œ
    batchCommands.push({
      sql: 'DELETE FROM schema_migrations WHERE id = ?',
      args: [migration.id]
    })
    
    await this.client.batch(batchCommands)
    
    console.log(`âœ… [DB] ë¡¤ë°± ì™„ë£Œ: ${migration.id}`)
  }

  async runMigrations(): Promise<void> {
    await this.createMigrationsTable()
    const appliedMigrations = await this.getAppliedMigrations()
    
    for (const migration of migrations) {
      if (!appliedMigrations.includes(migration.id)) {
        await this.applyMigration(migration)
      } else {
        console.log(`â­ï¸ [DB] ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í‚µ (ì´ë¯¸ ì ìš©ë¨): ${migration.id}`)
      }
    }
    
    console.log(`ğŸ‰ [DB] ëª¨ë“  ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ (${migrations.length}ê°œ)`)
  }

  async rollbackToMigration(targetMigrationId: string): Promise<void> {
    const appliedMigrations = await this.getAppliedMigrations()
    const targetIndex = migrations.findIndex(m => m.id === targetMigrationId)
    
    if (targetIndex === -1) {
      throw new Error(`ë§ˆì´ê·¸ë ˆì´ì…˜ ${targetMigrationId}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤`)
    }

    for (let i = migrations.length - 1; i > targetIndex; i--) {
      const migration = migrations[i]
      if (appliedMigrations.includes(migration.id)) {
        await this.rollbackMigration(migration)
      }
    }
  }
}